{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "genuine-tragedy",
   "metadata": {},
   "source": [
    "# Neural network based integrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dynamical_system import *\n",
    "from time_integrator import *\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2512517)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-mattress",
   "metadata": {},
   "source": [
    "## Neural network integrators\n",
    "Let $q(t)=(x(t),v(t))\\in\\mathbb{R}^{2d}$ be the state vector. Two methods are implemented to advance this state vector in time:\n",
    "\n",
    "### Multistep neural network\n",
    "The `MultistepNNInetgrator` class is used to implement a neural network based integrator with a $S$-step method. This is integrating a given $d$-dimensional system $\\frac{dq(t)}{dt}=\\mathcal{N}(q(t))$. The underlying neural model implements the mapping\n",
    "\n",
    "$$\n",
    "q^{(t-(S-1)\\Delta t)},\\dots,q^{(t-\\Delta t)},q^{(t)} \\mapsto q^{(t+\\Delta t)}\n",
    "$$\n",
    "\n",
    "Internally this is realised by mapping the $B\\times S \\times d$ tensor $X$ to the $B\\times d$ tensor $y$, where $B$ is the minibatch-size. This mapping is of the following form:\n",
    "\n",
    "$$\n",
    "y_{b,j} = X_{b,S-1,j} + \\Delta t \\cdot \\Phi_{bj}(X)\n",
    "$$\n",
    "\n",
    "where $\\Phi$ is a dense neural network. Note that for each batch index $b$, $X_{b,S-1,\\cdot}$ is simply the vector $q^{(t)}_b$, i.e. we assume that $q^{(t+\\Delta t)}$ is $q^{(t)}$ plus $\\Delta t$ times some correction. The neural network $\\Phi$ can take different form:\n",
    "* it can simply be a set of dense layers or\n",
    "* it can be a two-layer LSTM network, followed by a dense layer as in [https://arxiv.org/abs/2004.06493](https://arxiv.org/abs/2004.06493)\n",
    "\n",
    "### Hamiltonian neural network integrator\n",
    "Alternatively, the `HamiltonianNNIntegrator` implements a single-step Stoermer-Verlet method for a Hamiltonian system, following the ideas in [https://arxiv.org/abs/1906.01563](https://arxiv.org/abs/1906.01563). In this case the update $q^{(t)}\\mapsto q^{(t+\\Delta t)}$ takes the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v^{(t+\\Delta t/2)} &= v^{(t)} - \\frac{\\Delta t}{2} \\frac{\\partial V}{\\partial x}\\left(x^{(t)}\\right)\\\\[1ex]\n",
    "x^{(t+\\Delta t)} &= x^{(t)} + \\Delta t \\frac{\\partial T}{\\partial v}\\left(v^{(t+\\Delta t/2)}\\right)\\\\[1ex]\n",
    "v^{(t+\\Delta t)} &= v^{(t)} - \\frac{\\Delta t}{2} \\frac{\\partial V}{\\partial x}\\left(x^{(t+\\Delta t)}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Assuming that the Hamiltonian $H(x,v) = T(v) + V(x)$ is separable, the kinetic energy $T(v)$ and potential energy $V(x)$ are represented by neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNIntegrator(object):\n",
    "    '''Base class for neural network based integrators\n",
    "    \n",
    "    :arg dynamical_system: dynamical system used for integration\n",
    "    :arg dt: timestep size\n",
    "    :arg nsteps: number of multisteps\n",
    "    '''\n",
    "    def __init__(self,dynamical_system,dt,nsteps):\n",
    "        self.dynamical_system = dynamical_system\n",
    "        self.dt = dt        \n",
    "        self.dim = 2*self.dynamical_system.dim\n",
    "        self.nsteps = nsteps\n",
    "        self.xv = np.zeros((1,self.nsteps,self.dim))\n",
    "\n",
    "    def set_state(self,x,v):\n",
    "        '''Set the current state of the integrator\n",
    "        \n",
    "        :arg x: Array of size nsteps x dim with initial positions\n",
    "        :arg v: Array of size nsteps x dim with initial velocities\n",
    "        '''\n",
    "        self.xv[0,:,:self.dim//2] = x[:,:]\n",
    "        self.xv[0,:,self.dim//2:] = v[:,:]\n",
    "        \n",
    "    @property\n",
    "    def x(self):\n",
    "        '''Return the current position vector (as a d-dimensional array)'''\n",
    "        return self.xv[0,-1,:self.dim//2]\n",
    "\n",
    "    @property\n",
    "    def v(self):\n",
    "        '''Return the current velocity vector (as a d-dimensional array)'''\n",
    "        return self.xv[0,-1,self.dim//2:]\n",
    "    \n",
    "    def integrate(self,n_steps):\n",
    "        '''Carry out a given number of integration steps\n",
    "        \n",
    "        :arg n_steps: number of integration steps\n",
    "        '''\n",
    "        for k in range(n_steps):\n",
    "            x_pred = np.asarray(self.model.predict(self.xv)).flatten()\n",
    "            self.xv = np.roll(self.xv, -1, axis=1)\n",
    "            self.xv[0,-1,:] = x_pred[:]\n",
    "            \n",
    "    def energy(self):\n",
    "        return self.dynamical_system.energy(self.x,self.v)\n",
    "\n",
    "class MultistepNNIntegrator(NNIntegrator):\n",
    "    '''Multistep integrator. Use a neural network to predict the next state, given\n",
    "    a number of previous states\n",
    "    \n",
    "    :arg dynamical_system: dynamical system used for integration\n",
    "    :arg dt: timestep size\n",
    "    :arg nsteps: Number of steps of the timestepping method\n",
    "    :arg dense_layers: neural network layers used to predict the next state\n",
    "    '''\n",
    "    def __init__(self,dynamical_system,dt,nsteps,dense_layers):\n",
    "        super().__init__(dynamical_system,dt,nsteps)\n",
    "        self.dim = 2*self.dynamical_system.dim\n",
    "        self.dense_layers = dense_layers\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        inputs = keras.Input(shape=(self.nsteps,self.dim))\n",
    "        q_n = tf.unstack(inputs,axis=1)[-1]        \n",
    "        output_layer = keras.layers.Dense(self.dim)\n",
    "        x = inputs\n",
    "        for layer in dense_layers:\n",
    "            x = layer(x)\n",
    "        x = output_layer(x)\n",
    "        x = keras.layers.Rescaling(self.dt)(x)\n",
    "        outputs = keras.layers.Add()([q_n,x])\n",
    "        self.model = keras.Model(inputs=inputs,outputs=outputs)\n",
    "        self.model.compile(loss='mse',metrics=[],optimizer=keras.optimizers.Adam(learning_rate=1.E-4))\n",
    "        self.xv = np.zeros((1,self.nsteps,self.dim))\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        '''Evaluate model\n",
    "        \n",
    "        Split the inputs = (q_n,p_n) into position and momentum and \n",
    "        return the state (q_{n+1},p_{n+1}) at the next timestep.\n",
    "        \n",
    "        Note that the expected tensor shape is B x 1 x 2d to be compatible with\n",
    "        the non-symplectic update \n",
    "        \n",
    "        :arg inputs: state (q_n,p_n) as a B x 1 x 2d tensor\n",
    "        '''\n",
    "        \n",
    "        input_shape = tf.shape(inputs)\n",
    "        # Extract q_n and p_n from input\n",
    "        qp_old = tf.unstack(tf.reshape(inputs, (input_shape[0],input_shape[2],)),axis=-1)\n",
    "        q_old = tf.stack(qp_old[:self.dim//2],axis=-1)\n",
    "        p_old = tf.stack(qp_old[self.dim//2:],axis=-1)\n",
    "        q_new, p_new = self.verlet_step(q_old,p_old)        \n",
    "        # Combine result of Verlet step into tensor of correct size\n",
    "        outputs = tf.stack([q_new,p_new],axis=-1)        \n",
    "        return outputs\n",
    "\n",
    "class HamiltonianNNIntegrator(NNIntegrator):\n",
    "    '''Neural network integrator based on the Hamiltonian Stoermer-Verlet update'''\n",
    "    def __init__(self,dynamical_system,dt,V_pot_layers,T_kin_layers):\n",
    "        super().__init__(dynamical_system,dt,1)\n",
    "        self.V_pot_layers = V_pot_layers\n",
    "        self.T_kin_layers = T_kin_layers\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        self.model = VerletModel(self.dim,self.dt,\n",
    "                                 self.V_pot_layers,\n",
    "                                 self.T_kin_layers)\n",
    "        self.model.build(input_shape=(None,1,self.dim))\n",
    "        self.model.compile(loss='mse',metrics=[],optimizer=keras.optimizers.Adam(learning_rate=1.E-4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-shareware",
   "metadata": {},
   "source": [
    "### Set up system\n",
    "Set system parameters, construct dynamical system and integrator.\n",
    "\n",
    "The model system we are using here is the harmonic oscillator, defined by the equations of motion\n",
    "\n",
    "$$\n",
    "\\frac{dx}{dt} = v,\\qquad\\qquad\n",
    "\\frac{dv}{dt} = -\\frac{k}{m}x\n",
    "$$\n",
    "\n",
    "The timestep size of the Neural network integrator is set to $\\Delta t=40\\Delta t_{\\text{Verlet}}$ where $\\Delta t_{\\text{Verlet}}$ is the step size of the Verlet integrator that is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass of particle\n",
    "mass = 1.2\n",
    "# spring constant of harmonic oscillator\n",
    "k_spring = 0.9\n",
    "# timestep for Verlet integrator\n",
    "dt_verlet = 0.005\n",
    "# timestep for neural network integrator\n",
    "dt = 0.2\n",
    "# number of steps for multistep neural network integrator\n",
    "nsteps = 6\n",
    "\n",
    "# use Hamiltonian model?\n",
    "use_hamiltonian = True\n",
    "# use LSTM network for multistep integrator?\n",
    "use_LSTM = True\n",
    "\n",
    "# dynamical system to integrate\n",
    "harmonic_oscillator = HarmonicOscillator(mass,k_spring)\n",
    "# Verlet integrator used to generate data\n",
    "verlet_integrator = VerletIntegrator(harmonic_oscillator,dt_verlet)\n",
    "\n",
    "if use_hamiltonian:\n",
    "    V_pot_layers = [keras.layers.Dense(32,activation='tanh'),\n",
    "                    keras.layers.Dense(32,activation='tanh')]\n",
    "    T_kin_layers = [keras.layers.Dense(32,activation='tanh'),\n",
    "                    keras.layers.Dense(32,activation='tanh')]\n",
    "    nn_integrator = HamiltonianNNIntegrator(harmonic_oscillator,dt,V_pot_layers,T_kin_layers)    \n",
    "else:\n",
    "    if use_LSTM: \n",
    "        # Use two layers of LSTMs followed by a dense layer\n",
    "        dense_layers = [keras.layers.LSTM(64,return_sequences=True),\n",
    "                        keras.layers.LSTM(64),\n",
    "                        keras.layers.Dense(32,activation='tanh')]\n",
    "    else:\n",
    "        # Just use several dense layers\n",
    "        dense_layers = [keras.layers.Flatten(),\n",
    "                        keras.layers.Dense(32,activation='tanh'),\n",
    "                        keras.layers.Dense(64,activation='tanh'),\n",
    "                        keras.layers.Dense(32,activation='tanh')]\n",
    "\n",
    "\n",
    "    nn_integrator = MultistepNNIntegrator(harmonic_oscillator,dt,nsteps,\n",
    "                                          dense_layers)\n",
    "\n",
    "# visualise the neural network model\n",
    "nn_integrator.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-pledge",
   "metadata": {},
   "source": [
    "nn_integrator.nn_integrator.## Data generator\n",
    "The following data generator class can be used to construct training data samples of the form $(X_j,y_j)$ where\n",
    "\n",
    "$$\n",
    "X_j = q_j^{(0)},q_j^{(\\Delta t)},\\dots,q_j^{((S-1)\\Delta t)},\\qquad\\qquad y_j = q_j^{(S\\Delta t)}.\n",
    "$$\n",
    "\n",
    "Here $q_j^{(0)}$ is a randomly chosen initial condition and the states $q_j^{(\\Delta t)},q_j^{(2\\Delta t)},\\dots,q_j^{((S-1)\\Delta t)}, q_j^{(S\\Delta t)}$ are generated with a training generator (=Verlet) that is run with a smaller timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(self,nn_integrator,train_integrator):        \n",
    "        self.nn_integrator = nn_integrator\n",
    "        self.train_integrator = train_integrator\n",
    "        self.dynamical_system = self.nn_integrator.dynamical_system\n",
    "        self.dataset = tf.data.Dataset.from_generator(self._generator,                                                      \n",
    "                                                      output_signature=(\n",
    "                                                          tf.TensorSpec(shape=(self.nn_integrator.nsteps,\n",
    "                                                                               2*self.dynamical_system.dim), dtype=tf.float32),\n",
    "                                                          tf.TensorSpec(shape=(2*self.dynamical_system.dim), dtype=tf.float32)\n",
    "                                                      ))\n",
    "    \n",
    "    def _generator(self):\n",
    "        state = np.zeros((self.nn_integrator.nsteps+1,2*self.dynamical_system.dim))\n",
    "        while True:\n",
    "            self.dynamical_system.set_random_state(state[0,:self.dynamical_system.dim],\n",
    "                                                   state[0,self.dynamical_system.dim:])\n",
    "            self.train_integrator.set_state(state[0,:self.dynamical_system.dim],\n",
    "                                            state[0,self.dynamical_system.dim:])\n",
    "            for k in range(self.nn_integrator.nsteps):\n",
    "                self.train_integrator.integrate(int(self.nn_integrator.dt/self.train_integrator.dt))\n",
    "                state[k+1,:self.dynamical_system.dim] = self.train_integrator.x[:]\n",
    "                state[k+1,self.dynamical_system.dim:] = self.train_integrator.v[:]\n",
    "            X = state[:-1,:]\n",
    "            y = state[-1,:]\n",
    "            yield (X,y)\n",
    "    \n",
    "data_generator = DataGenerator(nn_integrator,verlet_integrator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-payroll",
   "metadata": {},
   "source": [
    "## Train neural network based integrator\n",
    "\n",
    "Note that training history can be visualised with tensorboard:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./tb_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-health",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "EPOCHS=400\n",
    "STEPS_PER_EPOCH=100\n",
    "log_dir = './tb_logs/'\n",
    "train_batches = data_generator.dataset.batch(BATCH_SIZE)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "result = nn_integrator.model.fit(train_batches,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                 callbacks=tensorboard_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-support",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "![Loss function](./loss_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-nicaragua",
   "metadata": {},
   "source": [
    "\n",
    "        #x = q**2## Plot trajectories generated by Verlet integrator and neural network based integrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final time\n",
    "T_final = 32\n",
    "\n",
    "# Initial conditions\n",
    "x = np.zeros(1)\n",
    "v = np.zeros(1)\n",
    "x[0] = 1.0\n",
    "v[0] = 0.0\n",
    "verlet_integrator.set_state(x,v)\n",
    "\n",
    "# ==== Verlet integrator ====\n",
    "t = 0.0\n",
    "t_verlet = []\n",
    "x_verlet = []\n",
    "E_verlet = []\n",
    "while t<T_final:\n",
    "    t_verlet.append(t)\n",
    "    E_verlet.append(verlet_integrator.energy())\n",
    "    x_verlet.append(verlet_integrator.x[0])\n",
    "    verlet_integrator.integrate(1)\n",
    "    t += dt_verlet\n",
    "        \n",
    "\n",
    "# ==== Neural network integrator ====\n",
    "\n",
    "# Initialise with Verlet integrator\n",
    "x_initial = np.zeros((nn_integrator.nsteps,nn_integrator.dynamical_system.dim))\n",
    "v_initial = np.zeros((nn_integrator.nsteps,nn_integrator.dynamical_system.dim))\n",
    "verlet_integrator.set_state(x,v)\n",
    "for k in range(nn_integrator.nsteps):    \n",
    "    x_initial[k,:] = verlet_integrator.x[:]\n",
    "    v_initial[k,:] = verlet_integrator.v[:]\n",
    "    verlet_integrator.integrate(int(dt/dt_verlet))\n",
    "nn_integrator.set_state(x_initial,v_initial)\n",
    "t = (nn_integrator.nsteps-1)*nn_integrator.dt\n",
    "\n",
    "# Timestepping loop\n",
    "t_nn = []\n",
    "x_nn = []\n",
    "E_nn = []\n",
    "while t<T_final:\n",
    "    t_nn.append(t)\n",
    "    x_nn.append(nn_integrator.x[0])\n",
    "    E_nn.append(nn_integrator.energy())\n",
    "    nn_integrator.integrate(1)\n",
    "    t += dt\n",
    "\n",
    "# Plot position as a function of time\n",
    "plt.plot(t_verlet,x_verlet,label='Verlet',color='blue')\n",
    "plt.plot(t_nn,x_nn,label='Neural network',color='red')\n",
    "plt.legend(loc='lower right')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('time $t$')\n",
    "ax.set_ylabel('position $x(t)$')\n",
    "ax.set_title('Position')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "# Plot energy as a function of time\n",
    "# (subtract energy at time t=0 to show energy drift)\n",
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].plot(t_verlet,E_verlet-E_verlet[0],label='Verlet',color='blue')\n",
    "axs[1].plot(t_nn,E_nn-E_nn[0],label='Neural network',color='red')\n",
    "plt.legend(loc='lower right')\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('time $t$')\n",
    "    ax.set_ylabel('energy shift $E(t)-E(t_0)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot potential and kinetic energy (for debugging)\n",
    "X = tf.expand_dims(tf.constant(np.arange(-2.0,2.0,0.01)),axis=1)\n",
    "\n",
    "V_pot = nn_integrator.model.V_pot(X).numpy().flatten()\n",
    "T_kin = nn_integrator.model.T_kin(X).numpy().flatten()\n",
    "plt.plot(X,V_pot,linewidth=2,color='blue',label='V(q)')\n",
    "plt.plot(X,T_kin,linewidth=2,color='red',label='T(p)')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('q / p')\n",
    "ax.set_ylabel('energy')\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a7366-a4d2-430d-9229-3ff77ab13244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_generator.dataset.batch(4)\n",
    "loss = 0\n",
    "for x in data.take(4):\n",
    "    print ('q_n         = ',x[0].numpy().flatten())\n",
    "    print ('q_n [true ] = ',x[1].numpy().flatten())\n",
    "    print ('q_n [pred ] = ',nn_integrator.model.predict(x[0]).flatten())\n",
    "    print (nn_integrator.model.predict(x[0]).shape)\n",
    "    print (x[1].shape)\n",
    "    nn_integrator.model.evaluate(x[0],x[1])\n",
    "    dx = x[1].numpy().flatten()-nn_integrator.model.predict(x[0]).flatten()\n",
    "    loss += dx[0]**2 + dx[1]**2\n",
    "print (' === loss = ',loss,' ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51026b85-2a61-445d-86eb-9b4a8e0430a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a669c-27f6-46c6-b4a1-e64d1e5aee94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
